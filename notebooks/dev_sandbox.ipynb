{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUjObDXhmg4j"
      },
      "source": [
        "# GEOEventFusion — Developer Sandbox\n",
        "\n",
        "Experimental scratch notebook for iterating on individual pipeline components  \n",
        "without running the full pipeline. Use this to:\n",
        "\n",
        "- Test individual agent logic in isolation\n",
        "- Inspect raw GDELT API responses\n",
        "- Prototype new analysis functions\n",
        "- Debug specific pipeline phases\n",
        "\n",
        "**This notebook is NOT the canonical entry point.** See `quickstart.ipynb` for production use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrD0uhy-mg4k"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dshipley71/GEOEventFusion.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPoeAvaEm19S",
        "outputId": "1dad077d-8593-4526-b93f-6f51e73b0364"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GEOEventFusion'...\n",
            "remote: Enumerating objects: 203, done.\u001b[K\n",
            "remote: Counting objects: 100% (203/203), done.\u001b[K\n",
            "remote: Compressing objects: 100% (184/184), done.\u001b[K\n",
            "remote: Total 203 (delta 36), reused 140 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (203/203), 253.75 KiB | 3.13 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd GEOEventFusion/\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpkNKJ6MnFF6",
        "outputId": "16ac2ee1-f6de-424f-abf1-74a93d5fce35"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GEOEventFusion\n",
            "AGENTS.md     DIRECTORY_STRUCTURE.md  \u001b[0m\u001b[01;34moutputs\u001b[0m/              \u001b[01;34mscripts\u001b[0m/\n",
            "CHANGELOG.md  \u001b[01;34mdocs\u001b[0m/                   pyproject.toml        skills.md\n",
            "CLAUDE.md     \u001b[01;34mgeoeventfusion\u001b[0m/         README.md             \u001b[01;34mtests\u001b[0m/\n",
            "\u001b[01;34mconfig\u001b[0m/       LICENSE                 requirements-dev.txt\n",
            "\u001b[01;34mdata\u001b[0m/         \u001b[01;34mnotebooks\u001b[0m/              requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements-dev.txt --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKrKHMGxm5BR",
        "outputId": "976502f1-4313-4350-c527-022b8edfc216"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (2.32.4)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.28.1)\n",
            "Collecting feedparser>=6.0.11 (from -r requirements.txt (line 10))\n",
            "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting trafilatura>=1.9.0 (from -r requirements.txt (line 11))\n",
            "  Downloading trafilatura-2.0.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting newspaper3k>=0.2.8 (from -r requirements.txt (line 12))\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: networkx>=3.2.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (3.6.1)\n",
            "Collecting anthropic>=0.34.0 (from -r requirements.txt (line 18))\n",
            "  Downloading anthropic-0.84.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting ollama>=0.3.0 (from -r requirements.txt (line 19))\n",
            "  Downloading ollama-0.6.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (1.2.1)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 23)) (2.12.3)\n",
            "Requirement already satisfied: pydantic-settings>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 24)) (2.13.1)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 25)) (6.0.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 29)) (1.16.3)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 30)) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 33)) (3.10.0)\n",
            "Requirement already satisfied: folium>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 34)) (0.20.0)\n",
            "Collecting Levenshtein>=0.25.0 (from -r requirements.txt (line 37))\n",
            "  Downloading levenshtein-0.27.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 38)) (2.9.0.post0)\n",
            "Requirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 41)) (4.67.3)\n",
            "Requirement already satisfied: pytest>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements-dev.txt (line 8)) (8.4.2)\n",
            "Collecting pytest-cov>=5.0.0 (from -r requirements-dev.txt (line 9))\n",
            "  Downloading pytest_cov-7.0.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting pytest-mock>=3.14.0 (from -r requirements-dev.txt (line 10))\n",
            "  Downloading pytest_mock-3.15.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting responses>=0.25.0 (from -r requirements-dev.txt (line 11))\n",
            "  Downloading responses-0.26.0-py3-none-any.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ruff>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements-dev.txt (line 14)) (0.15.2)\n",
            "Collecting mypy>=1.10.0 (from -r requirements-dev.txt (line 17))\n",
            "  Downloading mypy-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting types-requests>=2.31.0 (from -r requirements-dev.txt (line 18))\n",
            "  Downloading types_requests-2.32.4.20260107-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting types-PyYAML>=6.0.12 (from -r requirements-dev.txt (line 19))\n",
            "  Downloading types_pyyaml-6.0.12.20250915-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting types-python-dateutil>=2.9.0 (from -r requirements-dev.txt (line 20))\n",
            "  Downloading types_python_dateutil-2.9.0.20260124-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->-r requirements.txt (line 6)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->-r requirements.txt (line 6)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->-r requirements.txt (line 6)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->-r requirements.txt (line 6)) (2026.1.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->-r requirements.txt (line 7)) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->-r requirements.txt (line 7)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->-r requirements.txt (line 7)) (0.16.0)\n",
            "Collecting sgmllib3k (from feedparser>=6.0.11->-r requirements.txt (line 10))\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting courlan>=1.3.2 (from trafilatura>=1.9.0->-r requirements.txt (line 11))\n",
            "  Downloading courlan-1.3.2-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting htmldate>=1.9.2 (from trafilatura>=1.9.0->-r requirements.txt (line 11))\n",
            "  Downloading htmldate-1.9.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting justext>=3.0.1 (from trafilatura>=1.9.0->-r requirements.txt (line 11))\n",
            "  Downloading justext-3.0.2-py2.py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from trafilatura>=1.9.0->-r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k>=0.2.8->-r requirements.txt (line 12)) (4.13.5)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k>=0.2.8->-r requirements.txt (line 12)) (11.3.0)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k>=0.2.8->-r requirements.txt (line 12))\n",
            "  Downloading cssselect-1.4.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k>=0.2.8->-r requirements.txt (line 12)) (3.9.1)\n",
            "Collecting tldextract>=2.0.1 (from newspaper3k>=0.2.8->-r requirements.txt (line 12))\n",
            "  Downloading tldextract-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting feedfinder2>=0.0.4 (from newspaper3k>=0.2.8->-r requirements.txt (line 12))\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k>=0.2.8->-r requirements.txt (line 12))\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m114.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k>=0.2.8->-r requirements.txt (line 12))\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic>=0.34.0->-r requirements.txt (line 18)) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic>=0.34.0->-r requirements.txt (line 18)) (0.17.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic>=0.34.0->-r requirements.txt (line 18)) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic>=0.34.0->-r requirements.txt (line 18)) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic>=0.34.0->-r requirements.txt (line 18)) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.0->-r requirements.txt (line 23)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.0->-r requirements.txt (line 23)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.0->-r requirements.txt (line 23)) (0.4.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->-r requirements.txt (line 30)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->-r requirements.txt (line 30)) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 33)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 33)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 33)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 33)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 33)) (26.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 33)) (3.3.2)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from folium>=0.17.0->-r requirements.txt (line 34)) (0.8.2)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.12/dist-packages (from folium>=0.17.0->-r requirements.txt (line 34)) (3.1.6)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.12/dist-packages (from folium>=0.17.0->-r requirements.txt (line 34)) (2025.11.0)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein>=0.25.0->-r requirements.txt (line 37))\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.9.0->-r requirements.txt (line 38)) (1.17.0)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.2.0->-r requirements-dev.txt (line 8)) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.2.0->-r requirements-dev.txt (line 8)) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.2.0->-r requirements-dev.txt (line 8)) (2.19.2)\n",
            "Collecting coverage>=7.10.6 (from coverage[toml]>=7.10.6->pytest-cov>=5.0.0->-r requirements-dev.txt (line 9))\n",
            "  Downloading coverage-7.13.4-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (8.5 kB)\n",
            "Collecting mypy_extensions>=1.0.0 (from mypy>=1.10.0->-r requirements-dev.txt (line 17))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from mypy>=1.10.0->-r requirements-dev.txt (line 17))\n",
            "  Downloading pathspec-1.0.4-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting librt>=0.6.2 (from mypy>=1.10.0->-r requirements-dev.txt (line 17))\n",
            "  Downloading librt-0.8.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k>=0.2.8->-r requirements.txt (line 12)) (2.8.3)\n",
            "Requirement already satisfied: babel>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from courlan>=1.3.2->trafilatura>=1.9.0->-r requirements.txt (line 11)) (2.18.0)\n",
            "Collecting tld>=0.13 (from courlan>=1.3.2->trafilatura>=1.9.0->-r requirements.txt (line 11))\n",
            "  Downloading tld-0.13.1-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting dateparser>=1.1.2 (from htmldate>=1.9.2->trafilatura>=1.9.0->-r requirements.txt (line 11))\n",
            "  Downloading dateparser-1.3.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.9->folium>=0.17.0->-r requirements.txt (line 34)) (3.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k>=0.2.8->-r requirements.txt (line 12)) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k>=0.2.8->-r requirements.txt (line 12)) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k>=0.2.8->-r requirements.txt (line 12)) (2025.11.3)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k>=0.2.8->-r requirements.txt (line 12))\n",
            "  Downloading requests_file-3.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k>=0.2.8->-r requirements.txt (line 12)) (3.24.3)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura>=1.9.0->-r requirements.txt (line 11)) (5.3.1)\n",
            "Collecting lxml_html_clean (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura>=1.9.0->-r requirements.txt (line 11))\n",
            "  Downloading lxml_html_clean-0.4.4-py3-none-any.whl.metadata (2.4 kB)\n",
            "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trafilatura-2.0.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.84.0-py3-none-any.whl (455 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.2/455.2 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ollama-0.6.1-py3-none-any.whl (14 kB)\n",
            "Downloading levenshtein-0.27.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_cov-7.0.0-py3-none-any.whl (22 kB)\n",
            "Downloading pytest_mock-3.15.1-py3-none-any.whl (10 kB)\n",
            "Downloading responses-0.26.0-py3-none-any.whl (35 kB)\n",
            "Downloading mypy-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (13.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m146.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20260107-py3-none-any.whl (20 kB)\n",
            "Downloading types_pyyaml-6.0.12.20250915-py3-none-any.whl (20 kB)\n",
            "Downloading types_python_dateutil-2.9.0.20260124-py3-none-any.whl (18 kB)\n",
            "Downloading courlan-1.3.2-py3-none-any.whl (33 kB)\n",
            "Downloading coverage-7.13.4-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cssselect-1.4.0-py3-none-any.whl (18 kB)\n",
            "Downloading htmldate-1.9.4-py3-none-any.whl (31 kB)\n",
            "Downloading justext-3.0.2-py2.py3-none-any.whl (837 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.9/837.9 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading librt-0.8.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pathspec-1.0.4-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.2/55.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.3.1-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-3.0.1-py2.py3-none-any.whl (4.5 kB)\n",
            "Downloading tld-0.13.1-py2.py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml_html_clean-0.4.4-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13540 sha256=59b013ea6ccd397c8ff62707309ee912839c6024e934a286b6eac4f138699874\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/91/9f/00d66475960891a64867914273fcaf78df6cb04d905b104a2a\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3341 sha256=22091173262907073d5c86acd9f4226c083832603b41af60591991812ee3253a\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/9f/fb/364871d7426d3cdd4d293dcf7e53d97f160c508b2ccf00cc79\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398380 sha256=49cc073a480e6e6941810cba043f79e678352cfe145b8ec9e41f5d50925a1826\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/72/f7/fff392a8d4ea988dea4ccf9788599d09462a7f5e51e04f8a92\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=16351bdf612e2f3ec3db140ff25bc9491186a4c3dce58e63260a1bf03c3b2d7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, types-requests, types-PyYAML, types-python-dateutil, tld, rapidfuzz, pathspec, mypy_extensions, lxml_html_clean, librt, feedparser, cssselect, coverage, responses, requests-file, pytest-mock, mypy, Levenshtein, feedfinder2, dateparser, courlan, tldextract, pytest-cov, ollama, justext, htmldate, anthropic, trafilatura, newspaper3k\n",
            "Successfully installed Levenshtein-0.27.3 anthropic-0.84.0 courlan-1.3.2 coverage-7.13.4 cssselect-1.4.0 dateparser-1.3.0 feedfinder2-0.0.4 feedparser-6.0.12 htmldate-1.9.4 jieba3k-0.35.1 justext-3.0.2 librt-0.8.1 lxml_html_clean-0.4.4 mypy-1.19.1 mypy_extensions-1.1.0 newspaper3k-0.2.8 ollama-0.6.1 pathspec-1.0.4 pytest-cov-7.0.0 pytest-mock-3.15.1 rapidfuzz-3.14.3 requests-file-3.0.1 responses-0.26.0 sgmllib3k-1.0.0 tinysegmenter-0.3 tld-0.13.1 tldextract-5.3.1 trafilatura-2.0.0 types-PyYAML-6.0.12.20250915 types-python-dateutil-2.9.0.20260124 types-requests-2.32.4.20260107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cEuwbnWJn3ac",
        "outputId": "cee90b6c-81a6-40ab-cf85-fb63196575b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/GEOEventFusion'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FKbXgSVmg4k",
        "outputId": "1acb9e6c-5642-4e8d-927f-43ecdd7d3792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project root: /content\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import json\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure project root is on path when running from notebooks/\n",
        "_ROOT = Path().resolve().parent\n",
        "if str(_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(_ROOT))\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(levelname)-8s %(name)s — %(message)s')\n",
        "print(f'Project root: {_ROOT}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TFUYNpXmg4l",
        "outputId": "67edb766-9fd2-4dd1-9d15-0ba4ab86899f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config loaded: Houthi Red Sea attacks\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "from config.settings import PipelineConfig\n",
        "\n",
        "# Minimal test config — no real API calls\n",
        "config = PipelineConfig(\n",
        "    query='Houthi Red Sea attacks',\n",
        "    days_back=30,\n",
        "    llm_backend='ollama',\n",
        "    max_records=50,\n",
        "    test_mode=True,\n",
        "    log_level='DEBUG',\n",
        ")\n",
        "print('Config loaded:', config.query)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rich\n",
        "\n",
        "# TODO Fix default ollama host to ue cloud instead of local\n",
        "\n",
        "config.ollama_host = \"http://ollama.com\"\n",
        "rich.print(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7G6m6zuPoCOe",
        "outputId": "5e4f6553-6e73-4de7-92ee-6dd4be4019d6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mPipelineConfig\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33mquery\u001b[0m=\u001b[32m'Houthi Red Sea attacks'\u001b[0m,\n",
              "    \u001b[33mdays_back\u001b[0m=\u001b[1;36m30\u001b[0m,\n",
              "    \u001b[33mmax_records\u001b[0m=\u001b[1;36m50\u001b[0m,\n",
              "    \u001b[33mllm_backend\u001b[0m=\u001b[32m'ollama'\u001b[0m,\n",
              "    \u001b[33manthropic_model\u001b[0m=\u001b[32m'claude-sonnet-4-6'\u001b[0m,\n",
              "    \u001b[33mollama_model\u001b[0m=\u001b[32m'gemma3:27b'\u001b[0m,\n",
              "    \u001b[33mollama_host\u001b[0m=\u001b[32m'http://ollama.com'\u001b[0m,\n",
              "    \u001b[33mllm_temperature\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
              "    \u001b[33mllm_max_tokens\u001b[0m=\u001b[1;36m2048\u001b[0m,\n",
              "    \u001b[33mllm_min_max_tokens\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
              "    \u001b[33manthropic_api_key\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33macled_api_key\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33macled_email\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33mspike_z_threshold\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.5\u001b[0m,\n",
              "    \u001b[33mmax_spikes\u001b[0m=\u001b[1;36m10\u001b[0m,\n",
              "    \u001b[33mspike_backfill_hours\u001b[0m=\u001b[1;36m48\u001b[0m,\n",
              "    \u001b[33mdomain_cap_pct\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m,\n",
              "    \u001b[33mtimeline_smooth\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
              "    \u001b[33mrepeat_threshold\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
              "    \u001b[33mnear_window\u001b[0m=\u001b[1;36m15\u001b[0m,\n",
              "    \u001b[33mnear_min_term_length\u001b[0m=\u001b[1;36m5\u001b[0m,\n",
              "    \u001b[33mtone_negative_threshold\u001b[0m=\u001b[1;36m-5.0\u001b[0m,\n",
              "    \u001b[33mtoneabs_threshold\u001b[0m=\u001b[1;36m8\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
              "    \u001b[33mgdelt_stagger_seconds\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.75\u001b[0m,\n",
              "    \u001b[33mgdelt_max_workers\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
              "    \u001b[33mgdelt_max_retries\u001b[0m=\u001b[1;36m5\u001b[0m,\n",
              "    \u001b[33mgdelt_backoff_base\u001b[0m=\u001b[1;36m2\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
              "    \u001b[33mgdelt_request_timeout\u001b[0m=\u001b[1;36m30\u001b[0m,\n",
              "    \u001b[33msource_country_filter\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33msource_lang_filter\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33mauthoritative_domains\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
              "    \u001b[33mvisual_imagetags\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
              "    \u001b[33menable_visual_intel\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
              "    \u001b[33menable_word_clouds\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
              "    \u001b[33mrss_feed_list\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
              "    \u001b[33mrss_max_articles_per_spike\u001b[0m=\u001b[1;36m50\u001b[0m,\n",
              "    \u001b[33mrss_time_window_hours\u001b[0m=\u001b[1;36m48\u001b[0m,\n",
              "    \u001b[33mrss_request_timeout\u001b[0m=\u001b[1;36m15\u001b[0m,\n",
              "    \u001b[33mrss_dedup_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.85\u001b[0m,\n",
              "    \u001b[33mground_truth_sources\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
              "    \u001b[33mground_truth_country_filter\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
              "    \u001b[33mground_truth_event_types\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
              "    \u001b[33mcustom_dataset_path\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33mcustom_dataset_format\u001b[0m=\u001b[32m'csv'\u001b[0m,\n",
              "    \u001b[33mfusion_weights\u001b[0m=\u001b[1;35mFusionWeights\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtemporal\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.25\u001b[0m, \u001b[33mgeographic\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.25\u001b[0m, \u001b[33mactor\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33msemantic\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33mevent_type\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m\u001b[1m)\u001b[0m,\n",
              "    \u001b[33mfusion_temporal_window_hours\u001b[0m=\u001b[1;36m72\u001b[0m,\n",
              "    \u001b[33mfusion_geographic_threshold_km\u001b[0m=\u001b[1;36m200\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
              "    \u001b[33mmax_confidence\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.82\u001b[0m,\n",
              "    \u001b[33mmin_citations\u001b[0m=\u001b[1;36m3\u001b[0m,\n",
              "    \u001b[33mmin_panel_confidence\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.25\u001b[0m,\n",
              "    \u001b[33mvalidation_title_similarity_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.55\u001b[0m,\n",
              "    \u001b[33mvalidation_ground_truth_similarity_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.65\u001b[0m,\n",
              "    \u001b[33mvalidation_custom_match_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.5\u001b[0m,\n",
              "    \u001b[33mvalidation_date_delta_days\u001b[0m=\u001b[1;36m7\u001b[0m,\n",
              "    \u001b[33mvalidation_url_timeout\u001b[0m=\u001b[1;36m10\u001b[0m,\n",
              "    \u001b[33mvalidation_min_corroboration\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
              "    \u001b[33mactor_hub_top_n\u001b[0m=\u001b[1;36m5\u001b[0m,\n",
              "    \u001b[33mactor_broker_ratio_threshold\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.5\u001b[0m,\n",
              "    \u001b[33mactor_pagerank_max_iter\u001b[0m=\u001b[1;36m200\u001b[0m,\n",
              "    \u001b[33mvisual_staleness_hours\u001b[0m=\u001b[1;36m72\u001b[0m,\n",
              "    \u001b[33moutput_root\u001b[0m=\u001b[32m'outputs/runs'\u001b[0m,\n",
              "    \u001b[33mlog_level\u001b[0m=\u001b[32m'DEBUG'\u001b[0m,\n",
              "    \u001b[33mtest_mode\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PipelineConfig</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">query</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Houthi Red Sea attacks'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">days_back</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">max_records</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">llm_backend</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'ollama'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">anthropic_model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'claude-sonnet-4-6'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">ollama_model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gemma3:27b'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">ollama_host</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'http://ollama.com'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">llm_temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">llm_max_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">llm_min_max_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">anthropic_api_key</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">acled_api_key</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">acled_email</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">spike_z_threshold</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">max_spikes</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">spike_backfill_hours</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">domain_cap_pct</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">timeline_smooth</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">repeat_threshold</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">near_window</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">near_min_term_length</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">tone_negative_threshold</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5.0</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">toneabs_threshold</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.0</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">gdelt_stagger_seconds</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.75</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">gdelt_max_workers</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">gdelt_max_retries</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">gdelt_backoff_base</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">gdelt_request_timeout</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">source_country_filter</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">source_lang_filter</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">authoritative_domains</span>=<span style=\"font-weight: bold\">[]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">visual_imagetags</span>=<span style=\"font-weight: bold\">[]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">enable_visual_intel</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">enable_word_clouds</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">rss_feed_list</span>=<span style=\"font-weight: bold\">[]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">rss_max_articles_per_spike</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">rss_time_window_hours</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">rss_request_timeout</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">rss_dedup_threshold</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.85</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">ground_truth_sources</span>=<span style=\"font-weight: bold\">[]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">ground_truth_country_filter</span>=<span style=\"font-weight: bold\">[]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">ground_truth_event_types</span>=<span style=\"font-weight: bold\">[]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">custom_dataset_path</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">custom_dataset_format</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'csv'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">fusion_weights</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FusionWeights</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">temporal</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.25</span>, <span style=\"color: #808000; text-decoration-color: #808000\">geographic</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.25</span>, <span style=\"color: #808000; text-decoration-color: #808000\">actor</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">semantic</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">event_type</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span><span style=\"font-weight: bold\">)</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">fusion_temporal_window_hours</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">fusion_geographic_threshold_km</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200.0</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">max_confidence</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.82</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">min_citations</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">min_panel_confidence</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.25</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">validation_title_similarity_threshold</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.55</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">validation_ground_truth_similarity_threshold</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.65</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">validation_custom_match_threshold</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">validation_date_delta_days</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">validation_url_timeout</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">validation_min_corroboration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">actor_hub_top_n</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">actor_broker_ratio_threshold</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">actor_pagerank_max_iter</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">visual_staleness_hours</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">output_root</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'outputs/runs'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">log_level</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'DEBUG'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">test_mode</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEi6GnuHmg4l"
      },
      "source": [
        "## Test GDELT Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQaUr0qHmg4l",
        "outputId": "cbfd904e-0949-446b-9b0a-358f3f0e880e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:geoeventfusion.clients.gdelt_client:Failed to parse GDELT response body (length=52)\n",
            "WARNING:geoeventfusion.clients.gdelt_client:GDELT returned unparseable body for mode=ArtList\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GDELTClient fetch call to run a live query COMPLETED)\n"
          ]
        }
      ],
      "source": [
        "# Direct GDELT API call — inspect raw response\n",
        "from geoeventfusion.clients.gdelt_client import GDELTClient\n",
        "\n",
        "client = GDELTClient(\n",
        "    max_retries=config.gdelt_max_retries,\n",
        "    backoff_base=config.gdelt_backoff_base,\n",
        "    request_timeout=config.gdelt_request_timeout,\n",
        ")\n",
        "\n",
        "# TODO: Fix fetch to allow for timespan option vs start/end date\n",
        "\n",
        "# Fetch a small article list\n",
        "response = client.fetch(\n",
        "    query='ICE protests in Minneapolis',\n",
        "    mode='ArtList',\n",
        "    max_records=100,\n",
        "    sort='DateDesc',\n",
        "    start_date=\"20260101000000\", # YYYYMMDDHHMMSS or YYYY-MM-DD format\n",
        "    end_date=\"20260227000000\", # YYYYMMDDHHMMSS or YYYY-MM-DD format,\n",
        "    # timespan='7d',\n",
        ")\n",
        "\n",
        "print('GDELTClient fetch call to run a live query COMPLETED)')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of Articles: {len(response[\"articles\"])}\\n\")\n",
        "\n",
        "print(json.dumps(response, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "2We1wy2orqTs",
        "outputId": "03b12da2-4dfa-49a9-af3b-6ef20116e3e1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3217/3705521819.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of Articles: {len(response[\"\u001b[0m\u001b[0marticles\u001b[0m\u001b[0;34m\"])}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qOk8AY6mg4l"
      },
      "source": [
        "## Test Spike Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-gmH5Numg4n",
        "outputId": "432792f0-f5d8-4f21-f705-dcd4271f8963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timeline built from 100 articles across 1 day(s):\n",
            "  2026-02-27  articles=100\n",
            "\n",
            "(Need ≥3 data points for spike detection — fetch more articles or widen the date range.)\n"
          ]
        }
      ],
      "source": [
        "from geoeventfusion.analysis.spike_detector import detect_spikes\n",
        "from geoeventfusion.models.events import TimelineStep\n",
        "from collections import Counter\n",
        "\n",
        "articles = response.get(\"articles\", [])\n",
        "\n",
        "# ── Parse seendate → YYYY-MM-DD ──────────────────────────────────────────────\n",
        "def _parse_date(raw: str) -> str:\n",
        "    \"\"\"Normalise GDELT seendate variants to YYYY-MM-DD.\n",
        "    Handles: '20260220T120000Z', '2026-02-20', '20260220120000'.\n",
        "    \"\"\"\n",
        "    s = raw.replace(\"-\", \"\").replace(\"T\", \"\").replace(\"Z\", \"\").strip()\n",
        "    # s is now digits only, at least 8\n",
        "    return f\"{s[:4]}-{s[4:6]}-{s[6:8]}\"\n",
        "\n",
        "# ── Aggregate article count per calendar day ──────────────────────────────────\n",
        "date_counts: Counter = Counter()\n",
        "for art in articles:\n",
        "    raw_date = art.get(\"seendate\", \"\")\n",
        "    if raw_date:\n",
        "        try:\n",
        "            date_counts[_parse_date(raw_date)] += 1\n",
        "        except (ValueError, IndexError):\n",
        "            pass  # skip malformed dates\n",
        "\n",
        "if not date_counts:\n",
        "    print(\"No date data found in response — check that Cell 10 ran successfully.\")\n",
        "else:\n",
        "    # Build sorted TimelineStep list (one entry per day)\n",
        "    steps = [\n",
        "        TimelineStep(date=d, value=float(c))\n",
        "        for d, c in sorted(date_counts.items())\n",
        "    ]\n",
        "\n",
        "    print(f\"Timeline built from {len(articles)} articles across {len(steps)} day(s):\")\n",
        "    for s in steps:\n",
        "        print(f\"  {s.date}  articles={int(s.value)}\")\n",
        "\n",
        "    if len(steps) >= 3:\n",
        "        spikes = detect_spikes(steps, z_threshold=1.5)\n",
        "        print(f\"\\nDetected {len(spikes)} spike(s):\")\n",
        "        for s in spikes:\n",
        "            print(f\"  [{s.rank}] {s.date}  Z={s.z_score:.2f}  vol={s.volume}\")\n",
        "    else:\n",
        "        print(\"\\n(Need ≥3 data points for spike detection — fetch more articles or widen the date range.)\")\n",
        "\n",
        "# from geoeventfusion.analysis.spike_detector import detect_spikes\n",
        "# from geoeventfusion.models.events import TimelineStep\n",
        "\n",
        "# # Build a synthetic timeline with one clear spike\n",
        "# steps = [\n",
        "#     TimelineStep(date=f'2024-01-{i:02d}', value=2.0)\n",
        "#     for i in range(1, 28)\n",
        "# ]\n",
        "# steps[14] = TimelineStep(date='2024-01-15', value=9.5)  # Spike\n",
        "# steps[24] = TimelineStep(date='2024-01-25', value=8.0)  # Second spike\n",
        "\n",
        "# spikes = detect_spikes(steps, z_threshold=1.5)\n",
        "# print(f'Detected {len(spikes)} spikes:')\n",
        "# for s in spikes:\n",
        "#     print(f'  [{s.rank}] {s.date}  Z={s.z_score:.2f}  vol={s.volume}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNoWwesVmg4n"
      },
      "source": [
        "## Test Actor Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN9yYL55mg4n",
        "outputId": "d74c8d99-bd48-40f5-cd5f-b111a30f801e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes: 5  Edges: 5\n",
            "\n",
            "  Houthi                    role=Hub          pagerank=0.3193\n",
            "  United States             role=Hub          pagerank=0.3193\n",
            "  Iran                      role=Hub          pagerank=0.1657\n",
            "  Yemen                     role=Peripheral   pagerank=0.0979\n",
            "  United Kingdom            role=Peripheral   pagerank=0.0979\n"
          ]
        }
      ],
      "source": [
        "from geoeventfusion.analysis.actor_graph import build_actor_graph\n",
        "\n",
        "triples = [\n",
        "    ('Houthi', 'United States', '2024-01-15'),\n",
        "    ('Houthi', 'Yemen', '2024-01-15'),\n",
        "    ('United States', 'United Kingdom', '2024-01-16'),\n",
        "    ('Iran', 'Houthi', '2024-01-17'),\n",
        "    ('Houthi', 'United States', '2024-01-18'),\n",
        "    ('Iran', 'United States', '2024-01-19'),\n",
        "]\n",
        "\n",
        "graph = build_actor_graph(triples, hub_top_n=3, broker_ratio_threshold=0.5)\n",
        "print(f'Nodes: {len(graph.nodes)}  Edges: {len(graph.edges)}')\n",
        "print()\n",
        "for node in sorted(graph.nodes, key=lambda n: n.pagerank, reverse=True)[:5]:\n",
        "    print(f'  {node.name:<25} role={node.role:<12} pagerank={node.pagerank:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fherB6Cbmg4o"
      },
      "source": [
        "## Test Query Builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRhph8Q3mg4o"
      },
      "outputs": [],
      "source": [
        "from geoeventfusion.analysis.query_builder import QueryBuilder\n",
        "\n",
        "qb = QueryBuilder(\n",
        "    base_query='Houthi Red Sea attacks',\n",
        "    repeat_threshold=3,\n",
        "    near_window=15,\n",
        "    near_min_term_length=5,\n",
        "    tone_negative_threshold=-5.0,\n",
        "    toneabs_threshold=8.0,\n",
        ")\n",
        "\n",
        "# Build query variants\n",
        "print('Repeat query:    ', qb.build_repeat_query())\n",
        "print('Tone-neg query:  ', qb.build_tone_negative_query())\n",
        "print('High-emotion:    ', qb.build_high_emotion_query())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IUejAqPmg4p"
      },
      "source": [
        "## Test LLM Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6ulVP_amg4p"
      },
      "outputs": [],
      "source": [
        "from geoeventfusion.clients.llm_client import LLMClient\n",
        "\n",
        "# Instantiate (no call made yet)\n",
        "llm = LLMClient(\n",
        "    backend=config.llm_backend,\n",
        "    anthropic_model=config.anthropic_model,\n",
        "    ollama_model=config.ollama_model,\n",
        "    ollama_host=config.ollama_host,\n",
        "    anthropic_api_key=config.anthropic_api_key,\n",
        "    max_confidence=config.max_confidence,\n",
        ")\n",
        "print(f'LLMClient backend: {llm.backend}')\n",
        "print(f'Max confidence cap: {llm.max_confidence}')\n",
        "\n",
        "# Uncomment to make a live test call:\n",
        "# response = llm.call(\n",
        "#     system='You are a geopolitical analyst.',\n",
        "#     prompt='In one sentence, what is the Houthi movement?',\n",
        "#     max_tokens=100,\n",
        "# )\n",
        "# print('LLM response:', response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mveafmwmg4p"
      },
      "source": [
        "## Inspect Fixture Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZz0dW26mg4p"
      },
      "outputs": [],
      "source": [
        "# Load and inspect the test fixtures\n",
        "fixtures_dir = _ROOT / 'tests' / 'fixtures'\n",
        "\n",
        "with open(fixtures_dir / 'sample_artlist.json', encoding='utf-8') as f:\n",
        "    artlist = json.load(f)\n",
        "\n",
        "articles = artlist.get('articles', [])\n",
        "print(f'Fixture articles: {len(articles)}')\n",
        "for a in articles[:3]:\n",
        "    print(f'  [{a.get(\"seendate\", \"\")}] {a.get(\"title\", \"\")[:70]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zitPZCM_mg4p"
      },
      "source": [
        "## Run Full Pipeline (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXnue8e2mg4p"
      },
      "outputs": [],
      "source": [
        "# Uncomment to run the full pipeline with test fixtures (no real API calls)\n",
        "# from geoeventfusion.pipeline import run_pipeline\n",
        "# context = run_pipeline(config)\n",
        "# print(f'Run ID: {context.run_id}')\n",
        "# print(f'Warnings: {context.warnings}')\n",
        "print('Uncomment the block above to run the full pipeline in test mode.')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
