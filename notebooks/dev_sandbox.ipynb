{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEOEventFusion — Developer Sandbox\n",
    "\n",
    "Experimental scratch notebook for iterating on individual pipeline components  \n",
    "without running the full pipeline. Use this to:\n",
    "\n",
    "- Test individual agent logic in isolation\n",
    "- Inspect raw GDELT API responses\n",
    "- Prototype new analysis functions\n",
    "- Debug specific pipeline phases\n",
    "\n",
    "**This notebook is NOT the canonical entry point.** See `quickstart.ipynb` for production use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure project root is on path when running from notebooks/\n",
    "_ROOT = Path().resolve().parent\n",
    "if str(_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(_ROOT))\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)-8s %(name)s — %(message)s')\n",
    "print(f'Project root: {_ROOT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from config.settings import PipelineConfig\n",
    "\n",
    "# Minimal test config — no real API calls\n",
    "config = PipelineConfig(\n",
    "    query='Houthi Red Sea attacks',\n",
    "    days_back=30,\n",
    "    llm_backend='ollama',\n",
    "    max_records=50,\n",
    "    test_mode=True,\n",
    "    log_level='DEBUG',\n",
    ")\n",
    "print('Config loaded:', config.query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test GDELT Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct GDELT API call — inspect raw response\n",
    "from geoeventfusion.clients.gdelt_client import GDELTClient\n",
    "\n",
    "client = GDELTClient(\n",
    "    max_retries=config.gdelt_max_retries,\n",
    "    backoff_base=config.gdelt_backoff_base,\n",
    "    request_timeout=config.gdelt_request_timeout,\n",
    ")\n",
    "\n",
    "# Fetch a small article list\n",
    "# response = client.fetch(\n",
    "#     query='Houthi Red Sea',\n",
    "#     mode='ArtList',\n",
    "#     max_records=10,\n",
    "#     sort='DateDesc',\n",
    "#     timespan='7d',\n",
    "# )\n",
    "# print(json.dumps(response, indent=2)[:2000])\n",
    "print('GDELTClient instantiated (uncomment the fetch call to run a live query)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Spike Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoeventfusion.analysis.spike_detector import detect_spikes\n",
    "from geoeventfusion.models.events import TimelineStep\n",
    "\n",
    "# Build a synthetic timeline with one clear spike\n",
    "steps = [\n",
    "    TimelineStep(date=f'2024-01-{i:02d}', value=2.0)\n",
    "    for i in range(1, 28)\n",
    "]\n",
    "steps[14] = TimelineStep(date='2024-01-15', value=9.5)  # Spike\n",
    "steps[24] = TimelineStep(date='2024-01-25', value=8.0)  # Second spike\n",
    "\n",
    "spikes = detect_spikes(steps, z_threshold=1.5)\n",
    "print(f'Detected {len(spikes)} spikes:')\n",
    "for s in spikes:\n",
    "    print(f'  [{s.rank}] {s.date}  Z={s.z_score:.2f}  vol={s.volume}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Actor Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoeventfusion.analysis.actor_graph import build_actor_graph\n",
    "\n",
    "triples = [\n",
    "    ('Houthi', 'United States', '2024-01-15'),\n",
    "    ('Houthi', 'Yemen', '2024-01-15'),\n",
    "    ('United States', 'United Kingdom', '2024-01-16'),\n",
    "    ('Iran', 'Houthi', '2024-01-17'),\n",
    "    ('Houthi', 'United States', '2024-01-18'),\n",
    "    ('Iran', 'United States', '2024-01-19'),\n",
    "]\n",
    "\n",
    "graph = build_actor_graph(triples, hub_top_n=3, broker_ratio_threshold=0.5)\n",
    "print(f'Nodes: {len(graph.nodes)}  Edges: {len(graph.edges)}')\n",
    "print()\n",
    "for node in sorted(graph.nodes, key=lambda n: n.pagerank, reverse=True)[:5]:\n",
    "    print(f'  {node.name:<25} role={node.role:<12} pagerank={node.pagerank:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Query Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoeventfusion.analysis.query_builder import QueryBuilder\n",
    "\n",
    "qb = QueryBuilder(\n",
    "    base_query='Houthi Red Sea attacks',\n",
    "    repeat_threshold=3,\n",
    "    near_window=15,\n",
    "    near_min_term_length=5,\n",
    "    tone_negative_threshold=-5.0,\n",
    "    toneabs_threshold=8.0,\n",
    ")\n",
    "\n",
    "# Build query variants\n",
    "print('Repeat query:    ', qb.build_repeat_query())\n",
    "print('Tone-neg query:  ', qb.build_tone_negative_query())\n",
    "print('High-emotion:    ', qb.build_high_emotion_query())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test LLM Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoeventfusion.clients.llm_client import LLMClient\n",
    "\n",
    "# Instantiate (no call made yet)\n",
    "llm = LLMClient(\n",
    "    backend=config.llm_backend,\n",
    "    anthropic_model=config.anthropic_model,\n",
    "    ollama_model=config.ollama_model,\n",
    "    ollama_host=config.ollama_host,\n",
    "    anthropic_api_key=config.anthropic_api_key,\n",
    "    max_confidence=config.max_confidence,\n",
    ")\n",
    "print(f'LLMClient backend: {llm.backend}')\n",
    "print(f'Max confidence cap: {llm.max_confidence}')\n",
    "\n",
    "# Uncomment to make a live test call:\n",
    "# response = llm.call(\n",
    "#     system='You are a geopolitical analyst.',\n",
    "#     prompt='In one sentence, what is the Houthi movement?',\n",
    "#     max_tokens=100,\n",
    "# )\n",
    "# print('LLM response:', response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Fixture Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect the test fixtures\n",
    "fixtures_dir = _ROOT / 'tests' / 'fixtures'\n",
    "\n",
    "with open(fixtures_dir / 'sample_artlist.json', encoding='utf-8') as f:\n",
    "    artlist = json.load(f)\n",
    "\n",
    "articles = artlist.get('articles', [])\n",
    "print(f'Fixture articles: {len(articles)}')\n",
    "for a in articles[:3]:\n",
    "    print(f'  [{a.get(\"seendate\", \"\")}] {a.get(\"title\", \"\")[:70]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Full Pipeline (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run the full pipeline with test fixtures (no real API calls)\n",
    "# from geoeventfusion.pipeline import run_pipeline\n",
    "# context = run_pipeline(config)\n",
    "# print(f'Run ID: {context.run_id}')\n",
    "# print(f'Warnings: {context.warnings}')\n",
    "print('Uncomment the block above to run the full pipeline in test mode.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
